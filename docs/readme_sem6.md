# ğŸ§  Semana 6 â€“ Entrenamiento y EvaluaciÃ³n de Modelos Predictivos

## ğŸ¯ Objetivo del sprint
Implementar el pipeline de **modelado predictivo supervisado** para detectar **obras pÃºblicas con riesgo de corrupciÃ³n**, integrando los datasets de obras, empresas y funcionarios.  
Esta fase corresponde al **Sprint 6** del proyecto de tesis â€œSistema de DetecciÃ³n de Riesgos de CorrupciÃ³n en Obras PÃºblicas mediante Machine Learningâ€.

---

## âš™ï¸ 1. Contexto del proyecto

- **PropÃ³sito:** desarrollar un sistema que permita identificar obras pÃºblicas con indicadores de alto riesgo de corrupciÃ³n, utilizando fuentes oficiales y tÃ©cnicas de *machine learning*.
- **Datasets:** integrados a partir de los CSVs ubicados en `data/external/obra`, `empresa` y `funcionario`.
- **Salida procesada:**  
  - `data/processed/dataset_obras.parquet`  
  - `data/processed/dataset_integrado.parquet`
- **Variable objetivo:** `y_riesgo` (1 = Riesgo alto, 0 = Sin riesgo)
- **TamaÃ±o final del dataset integrado:** 14,179 filas Ã— 56 columnas.

---

## ğŸ§© 2. LÃ­nea base (baseline)

El modelo base utilizado fue **RegresiÃ³n LogÃ­stica**, con balanceo de clases (`class_weight="balanced"`).  
Este baseline permite establecer un punto de comparaciÃ³n para variantes mÃ¡s complejas.

**ConfiguraciÃ³n:**
```python
LogisticRegression(max_iter=1000, solver="lbfgs", class_weight="balanced")
```

**Advertencia tÃ©cnica:**  
El optimizador `lbfgs` alcanzÃ³ el lÃ­mite de iteraciones inicial (200), por lo que se ajustÃ³ a `max_iter=1000` para lograr convergencia estable sin afectar el rendimiento general del modelo.

---

## ğŸ§ª 3. Experimentos A/B

Se evaluaron **3 variantes principales** y una adicional opcional:

| Variante | Modelo | DescripciÃ³n tÃ©cnica |
|-----------|---------|---------------------|
| Var1 | Logistic Regression | LÃ­nea base con escalado y codificaciÃ³n categÃ³rica |
| Var2 | Random Forest | Ensamble con `n_estimators=200`, `class_weight="balanced_subsample"` |
| Var3 | XGBoost | Boosting con `max_depth=6`, `learning_rate=0.1`, `subsample=0.9` |
| (Opc.) | MLP | Red neuronal con capas ocultas (64, 32), activaciÃ³n ReLU |

**Preprocesamiento comÃºn:**
- ImputaciÃ³n de valores nulos (`SimpleImputer`)
- Escalado de variables numÃ©ricas (`StandardScaler`)
- CodificaciÃ³n de variables categÃ³ricas (`OneHotEncoder`)
- ValidaciÃ³n cruzada estratificada (k=5)

---

## ğŸ“Š 4. Resultados comparables

Los resultados se almacenan automÃ¡ticamente en `reports/metrics_semana6.csv`  
con las mÃ©tricas **F1**, **ROC-AUC**, **PR-AUC** y tiempo promedio de ejecuciÃ³n por modelo.

| Modelo | F1 | ROC-AUC | PR-AUC | Tiempo (s) | Seleccionado |
|:-------|---:|--------:|-------:|------------:|:-------------:|
| RegresiÃ³n LogÃ­stica | 0.67 | 0.74 | 0.70 | 3.5 | â€“ |
| Random Forest | 0.75 | 0.82 | 0.78 | 8.1 | â€“ |
| **XGBoost** | **0.81** | **0.88** | **0.84** | 5.4 | âœ… |
| MLP | 0.77 | 0.86 | 0.80 | 9.3 | â€“ |

ğŸ“ **Artefactos generados:**
- `models/pipeline.pkl` â†’ pipeline entrenado del mejor modelo  
- `models/pipeline_meta.json` â†’ metadatos del modelo  
- `reports/metrics_semana6.csv` â†’ registro acumulado de mÃ©tricas  
- `reports/figures/` â†’ grÃ¡ficas ROC y PR Curve  

---

## ğŸ§® 5. ValidaciÃ³n y sanidad

- DivisiÃ³n **estratificada** (80/20) sin *leakage* entre folds.  
- `random_state=42` para reproducibilidad.  
- Limpieza de columnas duplicadas y verificaciÃ³n de nulos (`SimpleImputer`).  
- RevisiÃ³n de correlaciones anÃ³malas en features numÃ©ricos.

---

## ğŸ§  6. ConclusiÃ³n tÃ©cnica

- **XGBoost** demostrÃ³ ser el modelo mÃ¡s robusto, logrando el mejor equilibrio entre precisiÃ³n, recall y estabilidad.  
- La imputaciÃ³n automÃ¡tica de valores faltantes y la normalizaciÃ³n mejoraron significativamente la convergencia.  
- Se estableciÃ³ un pipeline reproducible para futuras etapas de explicabilidad y despliegue.

---

## ğŸ§¾ 7. Reproducibilidad

### ğŸ§° Requisitos
```bash
pip install -r requirements.txt
```

### ğŸ—ï¸ ConstrucciÃ³n de datasets
```bash
python scripts/build_dataset_ml.py
python scripts/build_dataset_integrado.py
```

### ğŸ¤– Entrenamiento de modelos
```bash
python scripts/train_models.py --folds 5
```

### ğŸ“ˆ EvaluaciÃ³n y grÃ¡ficas
```bash
python scripts/eval_holdout.py
python scripts/plot_curves.py
```

---

## âš ï¸ 8. Riesgos y prÃ³ximos pasos

**Riesgos detectados:**
- Posible *data drift* entre fuentes 2023â€“2025.  
- Campos heterogÃ©neos entre dominios (obras, empresas, funcionarios).  
- Duplicidad de indicadores con distinto origen institucional.

**Acciones inmediatas (Semana 7):**
1. ExploraciÃ³n EDA avanzada (`EDA_Semana7.ipynb`)  
2. Interpretabilidad con **SHAP/LIME** sobre el modelo XGBoost.  
3. Refinamiento de variables mÃ¡s influyentes (`feature importance`).  
4. AnÃ¡lisis de sesgos y validaciÃ³n temporal cruzada.  
5. Preparar pipeline de despliegue para FastAPI / Docker.

---

## ğŸ“š 9. Referencias tÃ©cnicas

- Scikit-learn 1.5.0 â€” [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)  
- XGBoost Documentation â€” [https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)  
- ContralorÃ­a General de la RepÃºblica (CGR) â€“ Datos abiertos e informes institucionales (2023â€“2025).  
- Proyecto BID-3 (CT PE-T1600) â€“ Estrategia de fortalecimiento del control gubernamental.  

---

ğŸ“˜ **Autor:** Fernando GarcÃ­a - Hilario Aradiel  
ğŸ“… **Sprint:** Semana 6 â€“ Modelado Predictivo  
ğŸ“‚ **Repositorio:** [webconceptos/Deteccion_Corrupcion](https://github.com/webconceptos/Deteccion_Corrupcion)

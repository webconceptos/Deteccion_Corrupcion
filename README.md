# DetecciÃ³n de Riesgos de CorrupciÃ³n en Obras PÃºblicas (PerÃº)

Sistema de **Machine Learning** que integra seÃ±ales de **obra**, **empresa** y **miembro de comitÃ©** y etiqueta con la **Matriz de PriorizaciÃ³n** para clasificar obras como **riesgosas (1)** o **no riesgosas (0)**.

### Curso : Proyecto de InvestigaciÃ³n II
#### Integrantes: 
    Hilario Aradiel
    GarcÃ­a Fernando
---

## Estructura del repositorio

```
DETECCION_CORRUPCION/
â”œâ”€ data/
â”‚  â”œâ”€ raw/                  # datos fuente (solo lectura)
â”‚  â”œâ”€ interim/              # intermedios/temporales
â”‚  â”œâ”€ processed/            # dataset final para modelado (parquet)
â”‚  â””â”€ external/             # fuentes externas (si aplica)
â”œâ”€ models/
â”‚  â”œâ”€ pipeline.pkl          # pipeline sklearn (preprocesamiento + modelo)
â”‚  â””â”€ pipeline_meta.json    # metadatos (columnas, umbral, scores CV)
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_exploracion_diccionarios.ipynb
â”‚  â”œâ”€ 02_construir_dataset_maestro_final.ipynb
â”‚  â”œâ”€ 03_entrenamiento_evaluacion_final.ipynb
â”‚  â””â”€ EDA_baseline.ipynb
â”œâ”€ reports/
â”‚  â””â”€ figures/
â”‚     â”œâ”€ 01_target_dist.png
â”‚     â”œâ”€ 02_missing_top20.png
â”‚     â”œâ”€ 03_importance_perm.png
â”‚     â”œâ”€ 04_corr_heatmap.png
â”‚     â””â”€ 05_top_categorias.png
â”œâ”€ scripts/
â”‚  â”œâ”€ ingest.py             # ingesta con hash y logging
â”‚  â””â”€ preprocess.py         # limpieza mÃ­nima y verificaciÃ³n de processed
â”œâ”€ src/
â”‚  â”œâ”€ api/                  # FastAPI para servir el modelo
â”‚  â”œâ”€ config/ data/ features/ models/ utils/  # mÃ³dulos auxiliares
â”œâ”€ tests/
â”œâ”€ .env / .env.example
â”œâ”€ README.md
â””â”€ requirements.txt
```

---

## Objetivo

- **Problema:** identificar **obras con riesgo de corrupciÃ³n** a partir de informaciÃ³n administrativa y de ejecuciÃ³n.
- **Target:** `y_riesgo` (binario). En la versiÃ³n actual se deriva principalmente de `OBRA_RIESGO` / `OBRA_RIESGO_DESC` (Matriz 1A/2A/3A) tras normalizar llaves (`CODIGO_UNICO` â†” `COD_UNICO`/`CODIGO_OBRA`/`IDENTIFICADOR_OBRA`).
- **Dataset actual:** `data/processed/dataset_obras.parquet`.

---

## Reproducibilidad

### 1) Ingesta (copia a `data/raw/` + hash + log)
```bash
python scripts/ingest.py "C:/ruta/DS_DASH_Obra_1A.csv"
# salida: data/datasets.json (registro) y logs/ingest.log
```

### 2) Preprocesamiento mÃ­nimo (verificaciÃ³n y limpieza bÃ¡sica)
```bash
python scripts/preprocess.py
# salida: data/processed/dataset_obras.parquet y logs/preprocess.log
```

### 3) ConstrucciÃ³n del dataset maestro
Ejecutar notebooks en orden:

1. `01_exploracion_diccionarios.ipynb` â€“ mapeo/estandarizaciÃ³n de campos.  
2. `02_construir_dataset_maestro_final.ipynb` â€“ uniÃ³n Obra+Empresa+Miembro, etiquetado desde Matriz, limpieza y export a parquet (`dataset_obras.parquet`).  
3. `EDA_baseline.ipynb` â€“ genera figuras en `reports/figures/`.

### 4) Entrenamiento y evaluaciÃ³n
`03_entrenamiento_evaluacion_final.ipynb` compara modelos (**LogReg / RandomForest / GradientBoosting**) con **PR-AUC CV (5 folds)**, calcula **umbral Ã³ptimo por F1**, y guarda:

- `models/pipeline.pkl`  
- `models/pipeline_meta.json` (columnas, PR-AUC por modelo, `best_threshold_f1`)

---

## MÃ©tricas y grÃ¡ficos

- **ValidaciÃ³n:** **PR-AUC** (adecuada para desbalance), ademÃ¡s de ROC-AUC y `classification_report`.
- **Holdout:** 80/20 estratificado.
- **Figuras generadas** (ver `reports/figures/`):
  - `01_target_dist.png` â€“ distribuciÃ³n del target.  
  - `02_missing_top20.png` â€“ nulos por columna (Top 20).  
  - `03_importance_perm.png` â€“ *permutation importance* (Ã­ndices transformados).  
  - `04_corr_heatmap.png` â€“ matriz de correlaciÃ³n numÃ©rica.  
  - `05_top_categorias.png` â€“ top categorÃ­as (ej. `SECTOR`).

---

## ğŸš€ API (serving)

Ejecuta la API con **FastAPI** (en `src/api/`):

```bash
uvicorn src.api.main:app --reload
```

- `POST /predict_proba` â†’ `{ proba, threshold, riesgoso }`
  - Usa `models/pipeline.pkl` y `best_threshold_f1` de `models/pipeline_meta.json`.
- Importante: el JSON de entrada debe incluir **las mismas columnas** que espera el pipeline (nombres como en el parquet).

---

## âš™ï¸ Entorno

```bash
python -m venv .venv
# Windows:
.venv\Scripts\activate
# Linux/Mac:
# source .venv/bin/activate

pip install -r requirements.txt
```

Variables opcionales en `.env` (ver `.env.example`).

---

## ğŸ““ Notas de datos

- **Claves:**  
  - Obra: `CODIGO_UNICO` (variantes: `CODIGO_OBRA`, `IDENTIFICADOR_OBRA`).  
  - Matriz: `COD_UNICO` / `CODIGO_OBRA` / `IDENTIFICADOR_OBRA`.  
  - Empresa: `codigo_ruc`.  
  - Miembro: `codigo_dni`.

- **PrevenciÃ³n de fuga (leakage):** del entrenamiento se excluyen `OBRA_RIESGO`, `OBRA_RIESGO_DESC`, `PROYECTO_RIESGO`, `PROYECTO_RIESGO_DESC` y **todas las llaves**.

---

## âœ… Checklist del asesor

- [x] Repositorio con carpetas mÃ­nimas (`data/raw`, `notebooks`, `src/`).  
- [x] Dataset definido y disponible en `data/processed`.  
- [x] Scripts reproducibles: **ingesta** y **preprocesamiento** con **logs** y **hash**.  
- [x] EDA y **grÃ¡ficos** en `reports/figures/`.  
- [x] Baseline mÃ­nimo: comparaciÃ³n de modelos por **PR-AUC**, umbral Ã³ptimo, **pipeline** y **metadatos** guardados.  
- [x] API lista para demo interna.

---

## ğŸ—ºï¸ Roadmap corto

1. Aumentar clase negativa (0) y enriquecer features de Empresa/Miembro.  
2. CalibraciÃ³n de probabilidades (isotonic) y explicabilidad (SHAP/permutaciÃ³n detallada).  
3. OrquestaciÃ³n (Makefile/DVC) y Docker para despliegue.  

---

## ğŸ‘¥ CrÃ©ditos

Proyecto de tesis de maestrÃ­a: **DetecciÃ³n de Riesgos de CorrupciÃ³n en Obras PÃºblicas**.  
Autores / contacto: _[agregar nombres y correo]_

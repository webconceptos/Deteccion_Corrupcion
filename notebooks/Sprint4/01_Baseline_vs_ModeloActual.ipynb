{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97ddce9",
   "metadata": {},
   "source": [
    "### Sprint 4 – Notebook 01: Comparación Baseline vs Modelo Actual\n",
    "\n",
    "Este notebook analiza el desempeño del modelo baseline y del modelo actual optimizado.\n",
    "\n",
    "Incluye:\n",
    "\n",
    "- Carga de métricas generadas por los scripts del Sprint 4  \n",
    "- Comparación tabular  \n",
    "- Gráfico comparativo de métricas  \n",
    "- Ordenamiento por delta  \n",
    "- Comentarios y conclusiones  \n",
    "\n",
    "Las rutas ya están ajustadas para ejecutarse desde:  \n",
    "`notebooks/Sprint4/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48879fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aee71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('../../models/sprint4/resultados/metrics_baseline.csv'),\n",
       " WindowsPath('../../models/sprint4/resultados/metrics_modelo_actual.csv'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANTE:\n",
    "# El notebook está en notebooks/Sprint4/\n",
    "# Por eso las rutas suben dos niveles (../../)\n",
    "\n",
    "metrics_baseline_path = Path(\"../../models/sprint4/resultados/metrics_baseline.csv\")\n",
    "metrics_model_path = Path(\"../../models/sprint4/resultados/metrics_modelo_actual.csv\")\n",
    "\n",
    "metrics_baseline_path, metrics_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c65a74",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyDataError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metrics_model_path.exists():\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo existe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Ejecuta 02_run_inference_model_actual.py\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m mb = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_baseline_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m mm = pd.read_csv(metrics_model_path)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMétricas baseline:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IA_Investigacion\\Deteccion_Corrupcion\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IA_Investigacion\\Deteccion_Corrupcion\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IA_Investigacion\\Deteccion_Corrupcion\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IA_Investigacion\\Deteccion_Corrupcion\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IA_Investigacion\\Deteccion_Corrupcion\\env\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:581\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mEmptyDataError\u001b[39m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "if not metrics_baseline_path.exists():\n",
    "    raise FileNotFoundError(f\"No existe {metrics_baseline_path}. Ejecuta 01_run_inference_baseline.py\")\n",
    "\n",
    "if not metrics_model_path.exists():\n",
    "    raise FileNotFoundError(f\"No existe {metrics_model_path}. Ejecuta 02_run_inference_model_actual.py\")\n",
    "\n",
    "mb = pd.read_csv(metrics_baseline_path)\n",
    "mm = pd.read_csv(metrics_model_path)\n",
    "\n",
    "print(\"Métricas baseline:\")\n",
    "display(mb)\n",
    "\n",
    "print(\"Métricas modelo actual:\")\n",
    "display(mm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_dict = mb.iloc[0].to_dict()\n",
    "mm_dict = mm.iloc[0].to_dict()\n",
    "\n",
    "all_keys = sorted(set(mb_dict.keys()) | set(mm_dict.keys()))\n",
    "\n",
    "rows = []\n",
    "for k in all_keys:\n",
    "    v_b = mb_dict.get(k, float(\"nan\"))\n",
    "    v_m = mm_dict.get(k, float(\"nan\"))\n",
    "    try:\n",
    "        delta = float(v_m) - float(v_b)\n",
    "    except:\n",
    "        delta = float(\"nan\")\n",
    "\n",
    "    rows.append({\n",
    "        \"metrica\": k,\n",
    "        \"baseline\": v_b,\n",
    "        \"modelo_actual\": v_m,\n",
    "        \"delta\": delta,\n",
    "    })\n",
    "\n",
    "df_comp = pd.DataFrame(rows)\n",
    "df_comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_interes = [\n",
    "    \"accuracy\",\n",
    "    \"precision_macro\",\n",
    "    \"recall_macro\",\n",
    "    \"f1_macro\",\n",
    "    \"roc_auc\"\n",
    "]\n",
    "\n",
    "df_plot = df_comp[df_comp[\"metrica\"].isin(metricas_interes)].copy()\n",
    "df_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c45aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_plot.empty:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    x = range(len(df_plot))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.bar(\n",
    "        [i - width/2 for i in x],\n",
    "        df_plot[\"baseline\"],\n",
    "        width=width,\n",
    "        label=\"Baseline\"\n",
    "    )\n",
    "    plt.bar(\n",
    "        [i + width/2 for i in x],\n",
    "        df_plot[\"modelo_actual\"],\n",
    "        width=width,\n",
    "        label=\"Modelo Actual\"\n",
    "    )\n",
    "\n",
    "    plt.xticks(list(x), df_plot[\"metrica\"], rotation=45)\n",
    "    plt.ylabel(\"Valor de la métrica\")\n",
    "    plt.title(\"Comparación de métricas – Baseline vs Modelo Actual\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay métricas para graficar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_sorted = df_comp.sort_values(\"delta\", ascending=False)\n",
    "df_comp_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e10b4",
   "metadata": {},
   "source": [
    "#### Conclusiones preliminares\n",
    "\n",
    "- `f1_macro` y `recall_macro` suelen ser las métricas más relevantes cuando existe desbalance.  \n",
    "- `roc_auc` resume de forma global la capacidad discriminativa si está disponible.  \n",
    "- La columna `delta` permite cuantificar claramente la mejora del modelo actual frente al baseline.  \n",
    "\n",
    "Esta información se integra automáticamente en el informe generado por:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

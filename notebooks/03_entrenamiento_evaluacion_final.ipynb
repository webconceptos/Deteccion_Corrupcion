{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 · Entrenamiento y Evaluación (Pipeline sklearn)\n",
    "Usa `data/processed/dataset_obras.parquet` con `y_riesgo` como target.\n",
    "Guarda `models/pipeline.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo: c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\data\\processed\\dataset_obras.parquet\n",
      "Shape: (171, 53)\n",
      "Nulos por columna (top 15):\n",
      "DNI_MIEMBRO_COMITE               171\n",
      "CONVOCATORIA                     171\n",
      "CODIGO_RUC_PARTICIPANTE          171\n",
      "CODIGO_RUC_GANADOR               171\n",
      "NOMBRE_MIEMBRO_COMITE            171\n",
      "MES                              171\n",
      "Planificado                      171\n",
      "ANHO                             171\n",
      "IND_Monto_Adelanto_Directo       171\n",
      "IND_Monto_Adelanto_Materiales    171\n",
      "IND_Residente                    171\n",
      "IND_Intervension                 171\n",
      "Real                             171\n",
      "IND_Fecha_Adelanto_Directo       171\n",
      "IND_Fecha_Adelanto_Materiales    171\n",
      "dtype: int64\n",
      "\n",
      "Distribución target total:\n",
      "y_riesgo\n",
      "1    153\n",
      "0     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Eliminando columnas 100% NaN: ['CONVOCATORIA', 'DNI_MIEMBRO_COMITE', 'NOMBRE_MIEMBRO_COMITE', 'CODIGO_RUC_GANADOR', 'CODIGO_RUC_PARTICIPANTE', 'NOMBRE_PARTICIPANTE', 'EMPRESA_EJECUTORA', 'EMPRESA_SUPERVISORA', 'ANHO', 'MES', 'Planificado', 'Real', 'IND_Intervension', 'IND_Residente', 'IND_Monto_Adelanto_Materiales', 'IND_Monto_Adelanto_Directo', 'IND_Fecha_Adelanto_Materiales', 'IND_Fecha_Adelanto_Directo']\n",
      "Eliminando columnas constantes: ['TIEMPO_ABSOLUCION_CONSULTAS', 'TIEMPO_PRESENTACION_OFERTAS', 'Identificador_Obra', 'NOMBRE_EMPRESA_GANADORA', 'RUC_GANADOR', 'RUC_PARTICIPANTE', 'NOMBRE_EMPRESA_PARTICIPANTE', 'MONTO_OFERTADO', 'DIAS_PLAZO', 'TOTAL_CONTROL_PREVIO', 'TOTAL_CONTROL_SIMULTANEO', 'TOTAL_CONTROL_POSTERIOR']\n",
      "[Después de limpieza] Num cols: 9  Cat cols: 13  Total: 22\n",
      "Filas post-limpieza: 171\n",
      "Distribución target post-limpieza:\n",
      " y_riesgo\n",
      "1    153\n",
      "0     18\n",
      "Name: count, dtype: int64\n",
      "Split con test_size=0.200 -> train=136  test=35\n",
      "\n",
      "== Validación cruzada (PR-AUC) ==\n",
      "LogReg  PR-AUC CV: [0.9845 0.9884 0.9245 0.9666 0.9237]  → mean: 0.9575\n",
      "    RF  PR-AUC CV: [0.9963 0.9363 0.9934 0.9957 0.9694]  → mean: 0.9782\n",
      "    GB  PR-AUC CV: [0.9915 0.9615 0.9624 0.9903 0.9736]  → mean: 0.9759\n",
      "\n",
      "▶ Mejor por PR-AUC CV: RF (mean=0.9782)\n",
      "\n",
      "== RF (umbral 0.5) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.7500    0.7500         4\n",
      "           1     0.9677    0.9677    0.9677        31\n",
      "\n",
      "    accuracy                         0.9429        35\n",
      "   macro avg     0.8589    0.8589    0.8589        35\n",
      "weighted avg     0.9429    0.9429    0.9429        35\n",
      "\n",
      "ROC-AUC: 0.8145 | PR-AUC: 0.9603\n",
      "\n",
      "Umbral óptimo por F1: 0.436\n",
      "Matriz de confusión (umbral óptimo por F1) [0/1]:\n",
      "[[ 3  1]\n",
      " [ 0 31]]\n",
      "Precision: 0.9687 | Recall: 1.0000 | F1: 0.9841\n",
      "\n",
      "✅ Pipeline guardado en: c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\models\\pipeline.pkl\n",
      "✅ Metadatos guardados en: c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\models\\pipeline_meta.json\n"
     ]
    }
   ],
   "source": [
    "# === Notebook 03: Entrenamiento, selección y guardado del pipeline ===\n",
    "from pathlib import Path\n",
    "import json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Se omiten características sin ningún valor observado\")\n",
    "\n",
    "# --- Rutas y constantes ---\n",
    "BASE = Path.cwd().parents[0]\n",
    "DATA = BASE / \"data\" / \"processed\" / \"dataset_obras.parquet\"\n",
    "OUT_DIR = BASE / \"models\"\n",
    "OUT = OUT_DIR / \"pipeline.pkl\"\n",
    "META = OUT_DIR / \"pipeline_meta.json\"\n",
    "TARGET = \"y_riesgo\"\n",
    "\n",
    "# == 1) Cargar dataset ==\n",
    "print(\"Leyendo:\", DATA)\n",
    "df = pd.read_parquet(DATA)\n",
    "assert TARGET in df.columns, f\"No encuentra target: {TARGET}\"\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "print(\"Nulos por columna (top 15):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(15))\n",
    "\n",
    "y = df[TARGET].astype(int)\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "print(\"\\nDistribución target total:\")\n",
    "print(y.value_counts(dropna=False))\n",
    "\n",
    "# == 2) Limpieza de columnas problemáticas ==\n",
    "# 2.1 Quitar columnas 100% NaN\n",
    "all_nan = [c for c in X.columns if X[c].isna().all()]\n",
    "if all_nan:\n",
    "    print(\"\\nEliminando columnas 100% NaN:\", all_nan)\n",
    "    X = X.drop(columns=all_nan)\n",
    "\n",
    "# 2.2 Quitar columnas constantes (una sola categoría/valor)\n",
    "const_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]\n",
    "if const_cols:\n",
    "    print(\"Eliminando columnas constantes:\", const_cols)\n",
    "    X = X.drop(columns=const_cols)\n",
    "\n",
    "# 2.3 Re-detectar tipos\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "print(f\"[Después de limpieza] Num cols: {len(num_cols)}  Cat cols: {len(cat_cols)}  Total: {X.shape[1]}\")\n",
    "\n",
    "# == 3) Sanidad de filas y split estratificado robusto ==\n",
    "# Eliminar filas sin ninguna feature (todo NaN en num y en cat)\n",
    "if num_cols:\n",
    "    X_num = X[num_cols]\n",
    "else:\n",
    "    X_num = pd.DataFrame(index=X.index)\n",
    "if cat_cols:\n",
    "    X_cat = X[cat_cols]\n",
    "else:\n",
    "    X_cat = pd.DataFrame(index=X.index)\n",
    "\n",
    "rows_all_nan = (X_num.isna().all(axis=1) if len(X_num.columns) else True) & \\\n",
    "               (X_cat.isna().all(axis=1) if len(X_cat.columns) else True)\n",
    "\n",
    "n_drop = int(rows_all_nan.sum())\n",
    "if n_drop > 0:\n",
    "    print(\"Eliminando filas sin ninguna feature:\", n_drop)\n",
    "    X = X.loc[~rows_all_nan].copy()\n",
    "    y = y.loc[X.index].copy()\n",
    "\n",
    "print(\"Filas post-limpieza:\", len(X))\n",
    "print(\"Distribución target post-limpieza:\\n\", y.value_counts(dropna=False))\n",
    "\n",
    "# Split: asegurar al menos 1 minoritario en test\n",
    "minor = int(y.value_counts().min())\n",
    "ts_min = max(0.1, 1 / max(minor, 1))  # al menos 10% o 1 minoritario\n",
    "test_size = max(0.2, ts_min) if len(y) >= 10 else 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"Split con test_size={test_size:.3f} -> train={len(X_train)}  test={len(X_test)}\")\n",
    "\n",
    "# == 4) Preprocesamiento ==\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]), cat_cols)\n",
    "])\n",
    "\n",
    "# == 5) Comparación de modelos por PR-AUC (CV=5) ==\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=400, max_depth=10, min_samples_leaf=3,\n",
    "        class_weight=\"balanced\", n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    \"GB\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = {}\n",
    "print(\"\\n== Validación cruzada (PR-AUC) ==\")\n",
    "for name, m in models.items():\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", m)])\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"average_precision\")\n",
    "    cv_scores[name] = float(scores.mean())\n",
    "    print(f\"{name:>6}  PR-AUC CV: {np.round(scores,4)}  → mean: {scores.mean():.4f}\")\n",
    "\n",
    "best_name = max(cv_scores, key=cv_scores.get)\n",
    "best_model = models[best_name]\n",
    "print(f\"\\n▶ Mejor por PR-AUC CV: {best_name} (mean={cv_scores[best_name]:.4f})\")\n",
    "\n",
    "# == 6) Entrenar el mejor y evaluar ==\n",
    "clf = Pipeline([(\"pre\", pre), (\"model\", best_model)])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y probabilidades\n",
    "pred = clf.predict(X_test)\n",
    "proba = None\n",
    "try:\n",
    "    est = clf.named_steps[\"model\"]\n",
    "    classes = list(est.classes_)\n",
    "    pos_idx = classes.index(1) if 1 in classes else 1\n",
    "    proba = clf.predict_proba(X_test)[:, pos_idx]\n",
    "except Exception as e:\n",
    "    print(\"Predict_proba no disponible:\", e)\n",
    "\n",
    "print(f\"\\n== {best_name} (umbral 0.5) ==\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "best_thr = 0.5\n",
    "if proba is not None:\n",
    "    roc = roc_auc_score(y_test, proba)\n",
    "    prauc = average_precision_score(y_test, proba)\n",
    "    print(f\"ROC-AUC: {roc:.4f} | PR-AUC: {prauc:.4f}\")\n",
    "\n",
    "    # Umbral óptimo por F1\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, proba)\n",
    "    f1_scores = 2*precisions*recalls/(precisions+recalls+1e-9)\n",
    "    best_idx = f1_scores[:-1].argmax() if len(thresholds) else 0\n",
    "    best_thr = float(thresholds[best_idx]) if len(thresholds) else 0.5\n",
    "\n",
    "    pred_opt = (proba >= best_thr).astype(int)\n",
    "    cm = confusion_matrix(y_test, pred_opt, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"\\nUmbral óptimo por F1: {best_thr:.3f}\")\n",
    "    print(\"Matriz de confusión (umbral óptimo por F1) [0/1]:\")\n",
    "    print(cm)\n",
    "    print(f\"Precision: {tp/(tp+fp+1e-9):.4f} | Recall: {tp/(tp+fn+1e-9):.4f} | F1: {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "# == 7) Guardar pipeline y metadatos ==\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(clf, OUT)\n",
    "meta = {\n",
    "    \"target\": TARGET,\n",
    "    \"num_cols\": num_cols,\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"best_model\": best_name,\n",
    "    \"cv_pr_auc\": cv_scores,\n",
    "    \"best_threshold_f1\": best_thr\n",
    "}\n",
    "META.write_text(json.dumps(meta, indent=2, ensure_ascii=False))\n",
    "print(\"\\n✅ Pipeline guardado en:\", OUT)\n",
    "print(\"✅ Metadatos guardados en:\", META)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

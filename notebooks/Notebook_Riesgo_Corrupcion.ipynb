{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9c98e0",
   "metadata": {},
   "source": [
    "# Sistema ML: Detección de **Riesgo de Corrupción** en Obras Públicas (Perú)\n",
    "\n",
    "Este notebook implementa un *pipeline* end-to-end para detectar obras públicas con **riesgo de corrupción**:\n",
    "1) **Ingesta** de datos (simulada si no se detectan archivos reales).  \n",
    "2) **ETL** y *feature engineering* con banderas de riesgo.  \n",
    "3) Entrenamiento de **modelos** (*baseline* y árbol de decisión/ensamble).  \n",
    "4) **Evaluación** con métricas y curvas.  \n",
    "5) **XAI**: Importancia por permutación y **PDP/ICE**.  \n",
    "6) **Exportación** de artefactos (pipeline + modelo) y función de inferencia.\n",
    "\n",
    "> ⚠️ Reemplace los *placeholders* de rutas por sus fuentes reales (SIAF, SEACE/OSCE, INFObras, Módulos CGR/BID, etc.) cuando estén disponibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b01a1",
   "metadata": {},
   "source": [
    "## Contexto y objetivo\n",
    "\n",
    "En el marco de la **Contraloría (CGR)** y el proyecto **BID‑3**, buscamos **priorizar** y **alertar** sobre obras con probabilidad de incurrir en **riesgos de corrupción** (p. ej., adicionales y ampliaciones atípicas, fraccionamiento, sanciones previas de empresas, colusión, sobrecostos, baja competencia, etc.).\n",
    "\n",
    "**Variable objetivo (label)**: `riesgo_corrupcion` (1 = alto riesgo, 0 = bajo riesgo).  \n",
    "**Fuentes típicas:** SIAF, SEACE/OSCE, INFOBRAS, PERUCOMPRAS, SERVIR, SNCP, padrones de sanciones, y registros internos de la CGR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfab99ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\notebooks\n",
      "DATA_ROOT: c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\data\\external\n"
     ]
    }
   ],
   "source": [
    "# == 0) Config & utilidades\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
    "\n",
    "\n",
    "def find_data_root(start: Path) -> Path | None:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\" / \"external\").is_dir():\n",
    "            return p / \"data\" / \"external\"\n",
    "    return None\n",
    "\n",
    "\n",
    "DATA_ROOT = find_data_root(Path.cwd())\n",
    "# DATA_ROOT = Path(r'/ruta/absoluta/a/tu/proyecto/data/external')  # descomenta y ajusta si es necesario\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "\n",
    "ARTIF_DIR = Path(\"artifacts\")\n",
    "ARTIF_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def save_df(df: pd.DataFrame, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        import pyarrow  # noqa\n",
    "\n",
    "        if path.suffix.lower() != \".parquet\":\n",
    "            path = path.with_suffix(\".parquet\")\n",
    "        df.to_parquet(path, index=False)\n",
    "        print(\"[SAVE] Parquet ->\", path)\n",
    "    except Exception:\n",
    "        if path.suffix.lower() != \".csv\":\n",
    "            path = path.with_suffix(\".csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        print(\"[SAVE] CSV ->\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c1437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obra        : c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\data\\external\\obra exists? True\n",
      "  ejemplos: ['Datos generales - Obra - 2025.05.15.xlsx', 'DS_DASH_Obra_1A.csv', 'DS_DASH_Obra_2A_3A.csv', 'DS_DASH_Obra_2B.csv', 'DS_DASH_Obra_3B.csv']\n",
      "empresa     : c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\data\\external\\empresa exists? True\n",
      "  ejemplos: ['Datos generales - Empresa -2023.05.15.xlsx', 'DS_DASH_Empresa_1A.csv', 'DS_DASH_Empresa_1B.csv', 'DS_DASH_Empresa_2A.csv', 'DS_DASH_Empresa_2B.csv']\n",
      "funcionario : c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\data\\external\\funcionario exists? True\n",
      "  ejemplos: ['Datos generales - Funcionario - 2025.05.15.xlsx', 'DS_DASH_Miembro_1A.csv', 'DS_DASH_Miembro_2A.csv', 'DS_DASH_Miembro_3A.csv', 'DS_DASH_Miembro_3B.csv']\n",
      "catalogos   : c:\\MaestriaUNI\\Cursos\\III-CICLO\\TesisI\\Solucion\\Deteccion_Corrupcion\\data\\external\\catalogos exists? True\n",
      "  ejemplos: ['Diccionario vistas dashboards y datasets.xlsx', 'diccionario_campos.xlsx', 'Diccionario_Datos_ML_Completo_V1.xlsx', 'Diccionario_Datos_Sistemas_Fuente_V1.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# == 0.1) Diagnóstico\n",
    "if DATA_ROOT is not None:\n",
    "    for sub in [\"obra\", \"empresa\", \"funcionario\", \"catalogos\"]:\n",
    "        p = DATA_ROOT / sub\n",
    "        print(f\"{sub:12s}:\", p, \"exists?\", p.exists())\n",
    "        if p.exists():\n",
    "            print(\"  ejemplos:\", [x.name for x in list(p.iterdir())[:5]])\n",
    "else:\n",
    "    print(\"No se detectó data/external. Ajusta DATA_ROOT manualmente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe44aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Obra] shape: (14344, 58)  [Empresa] shape: (8523, 29)  [Func] shape: (5629, 20)\n",
      "[SAVE] Parquet -> data\\bronze\\obra_raw.parquet\n",
      "[SAVE] CSV -> data\\bronze\\empresa_raw.csv\n",
      "[SAVE] Parquet -> data\\bronze\\funcionario_raw.parquet\n"
     ]
    }
   ],
   "source": [
    "# == 1) Ingesta robusta\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "assert DATA_ROOT is not None, \"Ajusta DATA_ROOT en la celda de Config.\"\n",
    "\n",
    "P_OBRA = DATA_ROOT / \"obra\"\n",
    "P_EMP = DATA_ROOT / \"empresa\"\n",
    "P_FUNC = DATA_ROOT / \"funcionario\"\n",
    "\n",
    "\n",
    "def read_any(path: Path) -> pd.DataFrame:\n",
    "    if path.suffix.lower() in (\".xlsx\", \".xls\"):\n",
    "        return pd.read_excel(path)\n",
    "    for enc in (\"utf-8-sig\", \"latin-1\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def concat_many(folder: Path, patterns):\n",
    "    files = []\n",
    "    for pat in patterns:\n",
    "        files += list(folder.glob(pat))\n",
    "    files = sorted(set(files))\n",
    "    if not files:\n",
    "        return pd.DataFrame()\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = read_any(f)\n",
    "            df[\"_source\"] = f.name\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN]\", f.name, \"->\", e)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "\n",
    "obra_raw = concat_many(P_OBRA, [\"DS_DASH_Obra_*.*\", \"Datos generales*Obra*.*\"])\n",
    "emp_raw = concat_many(P_EMP, [\"DS_DASH_Empresa_*.*\", \"Datos generales*Empresa*.*\"])\n",
    "func_raw = concat_many(P_FUNC, [\"DS_DASH_Miembro_*.*\", \"Datos generales*Funcion*.*\"])\n",
    "\n",
    "print(\n",
    "    \"[Obra] shape:\",\n",
    "    obra_raw.shape,\n",
    "    \" [Empresa] shape:\",\n",
    "    emp_raw.shape,\n",
    "    \" [Func] shape:\",\n",
    "    func_raw.shape,\n",
    ")\n",
    "\n",
    "save_df(obra_raw, Path(\"data/bronze/obra_raw\"))\n",
    "save_df(emp_raw, Path(\"data/bronze/empresa_raw\"))\n",
    "save_df(func_raw, Path(\"data/bronze/funcionario_raw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9384c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SILVER obra shape: (14344, 72)\n",
      "[SAVE] Parquet -> data\\silver\\obra_silver.parquet\n"
     ]
    }
   ],
   "source": [
    "# == 2) Estandarización + limpieza (SILVER)\n",
    "import pandas as pd\n",
    "\n",
    "colmap_obras = {\n",
    "    \"costo_total\": [\"MontoContrato\", \"CostoTotal\", \"costo_total\", \"Monto total\", \"Monto_total\"],\n",
    "    \"plazo_meses\": [\"PlazoMeses\", \"plazo_meses\", \"Plazo (meses)\"],\n",
    "    \"adicionales_pct\": [\"AdicPct\", \"%Adicionales\", \"adicionales_pct\", \"Porc_Adicionales\"],\n",
    "    \"ampliaciones\": [\"NroAmpliaciones\", \"ampliaciones\"],\n",
    "    \"penalidades\": [\"NroPenalidades\", \"penalidades\"],\n",
    "    \"baja_competencia\": [\"BajaCompetencia\", \"baja_competencia\", \"PocosPostores\"],\n",
    "    \"consorcio\": [\"Consorcio\", \"consorcio\"],\n",
    "    \"experiencia_entidad\": [\"ExperienciaEntidad\", \"experiencia_entidad\"],\n",
    "    \"region_riesgo\": [\"RegionRiesgo\", \"region_riesgo\"],\n",
    "    \"tipo_proceso\": [\"TipoProceso\", \"tipo_proceso\"],\n",
    "    \"RUC\": [\"RUC\", \"ruc\"],\n",
    "    \"CUI\": [\"CUI\", \"cui\"],\n",
    "    \"riesgo_corrupcion\": [\"riesgo_corrupcion\"],\n",
    "}\n",
    "colmap_empresa = {\n",
    "    \"RUC\": [\"RUC\", \"ruc\"],\n",
    "    \"empresa_sancionada\": [\"EmpresaSancionada\", \"SancionOSCE\", \"empresa_sancionada\"],\n",
    "}\n",
    "\n",
    "\n",
    "def standardize(df, colmap):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    out = df.copy()\n",
    "    for std, variants in colmap.items():\n",
    "        for v in variants:\n",
    "            if v in out.columns:\n",
    "                out[std] = out[v]\n",
    "                break\n",
    "        if std not in out.columns:\n",
    "            out[std] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "obra = standardize(obra_raw, colmap_obras)\n",
    "emp = standardize(emp_raw, colmap_empresa)\n",
    "\n",
    "\n",
    "def to_num(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace(\"S/.\", \"\").replace(\",\", \"\").strip()\n",
    "        x = re.sub(r\"[^0-9\\\\.-eE]\", \"\", x)\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "for c in [\n",
    "    \"costo_total\",\n",
    "    \"plazo_meses\",\n",
    "    \"adicionales_pct\",\n",
    "    \"ampliaciones\",\n",
    "    \"penalidades\",\n",
    "    \"baja_competencia\",\n",
    "    \"consorcio\",\n",
    "    \"experiencia_entidad\",\n",
    "]:\n",
    "    if c in obra.columns:\n",
    "        obra[c] = obra[c].map(to_num)\n",
    "\n",
    "if \"adicionales_pct\" in obra.columns:\n",
    "    obra.loc[obra[\"adicionales_pct\"] > 1, \"adicionales_pct\"] = obra[\"adicionales_pct\"] / 100.0\n",
    "\n",
    "\n",
    "def norm_tipo(s):\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    s = str(s).lower()\n",
    "    if \"directa\" in s:\n",
    "        return \"Contratación Directa\"\n",
    "    if \"simplificada\" in s:\n",
    "        return \"Adjudicación Simplificada\"\n",
    "    return \"Licitación\"\n",
    "\n",
    "\n",
    "def norm_region(s):\n",
    "    if pd.isna(s):\n",
    "        return \"MEDIA\"\n",
    "    s = str(s).upper()\n",
    "    return s if s in {\"ALTA\", \"MEDIA\", \"BAJA\"} else \"MEDIA\"\n",
    "\n",
    "\n",
    "if \"tipo_proceso\" in obra.columns:\n",
    "    obra[\"tipo_proceso\"] = obra[\"tipo_proceso\"].apply(norm_tipo)\n",
    "obra[\"region_riesgo\"] = obra.get(\"region_riesgo\", \"MEDIA\")\n",
    "obra[\"region_riesgo\"] = obra[\"region_riesgo\"].apply(norm_region)\n",
    "\n",
    "\n",
    "def norm_ruc(x):\n",
    "    s = re.sub(r\"[^0-9]\", \"\", str(x) if x is not None else \"\")\n",
    "    return s.zfill(11) if len(s) == 11 else s\n",
    "\n",
    "\n",
    "if \"RUC\" in obra.columns:\n",
    "    obra[\"RUC\"] = obra[\"RUC\"].map(norm_ruc)\n",
    "if \"RUC\" in emp.columns:\n",
    "    emp[\"RUC\"] = emp[\"RUC\"].map(norm_ruc)\n",
    "\n",
    "obra[\"empresa_sancionada\"] = obra.get(\"empresa_sancionada\", np.nan)\n",
    "\n",
    "if not emp.empty and \"RUC\" in emp.columns:\n",
    "    emp_aux = emp[[\"RUC\", \"empresa_sancionada\"]].dropna(subset=[\"RUC\"]).copy()\n",
    "    if emp_aux[\"empresa_sancionada\"].dtype == object:\n",
    "        emp_aux[\"empresa_sancionada\"] = (\n",
    "            emp_aux[\"empresa_sancionada\"]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .map({\"si\": 1, \"sí\": 1, \"true\": 1, \"1\": 1, \"no\": 0, \"false\": 0, \"0\": 0})\n",
    "            .fillna(0)\n",
    "            .astype(\"int8\")\n",
    "        )\n",
    "    else:\n",
    "        emp_aux[\"empresa_sancionada\"] = (\n",
    "            pd.to_numeric(emp_aux[\"empresa_sancionada\"], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "        )\n",
    "    emp_map = (\n",
    "        emp_aux.groupby(\"RUC\", as_index=True)[\"empresa_sancionada\"].max().astype(\"int8\").to_dict()\n",
    "    )\n",
    "    obra[\"empresa_sancionada_emp\"] = obra[\"RUC\"].map(emp_map).fillna(0).astype(\"int8\")\n",
    "    obra[\"empresa_sancionada\"] = (\n",
    "        pd.to_numeric(obra[\"empresa_sancionada\"], errors=\"coerce\")\n",
    "        .fillna(obra[\"empresa_sancionada_emp\"])\n",
    "        .fillna(0)\n",
    "        .astype(\"int8\")\n",
    "    )\n",
    "    obra.drop(columns=[\"empresa_sancionada_emp\"], inplace=True)\n",
    "\n",
    "for c in [\n",
    "    \"plazo_meses\",\n",
    "    \"ampliaciones\",\n",
    "    \"penalidades\",\n",
    "    \"baja_competencia\",\n",
    "    \"consorcio\",\n",
    "    \"experiencia_entidad\",\n",
    "    \"empresa_sancionada\",\n",
    "]:\n",
    "    if c in obra.columns:\n",
    "        obra[c] = pd.to_numeric(obra[c], errors=\"coerce\", downcast=\"integer\")\n",
    "if \"costo_total\" in obra.columns:\n",
    "    obra[\"costo_total\"] = pd.to_numeric(obra[\"costo_total\"], errors=\"coerce\", downcast=\"float\")\n",
    "if \"adicionales_pct\" in obra.columns:\n",
    "    obra[\"adicionales_pct\"] = pd.to_numeric(\n",
    "        obra[\"adicionales_pct\"], errors=\"coerce\", downcast=\"float\"\n",
    "    )\n",
    "\n",
    "for c in [\"region_riesgo\", \"tipo_proceso\", \"_source\"]:\n",
    "    if c in obra.columns and obra[c].dtype == \"object\":\n",
    "        obra[c] = obra[c].astype(\"category\")\n",
    "\n",
    "print(\"SILVER obra shape:\", obra.shape)\n",
    "save_df(obra, Path(\"data/silver/obra_silver\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d54e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD df shape: (14344, 12)\n",
      "[SAVE] Parquet -> data\\gold\\obras_ml.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>costo_total</th>\n",
       "      <th>plazo_meses</th>\n",
       "      <th>adicionales_pct</th>\n",
       "      <th>ampliaciones</th>\n",
       "      <th>penalidades</th>\n",
       "      <th>baja_competencia</th>\n",
       "      <th>empresa_sancionada</th>\n",
       "      <th>consorcio</th>\n",
       "      <th>experiencia_entidad</th>\n",
       "      <th>region_riesgo</th>\n",
       "      <th>tipo_proceso</th>\n",
       "      <th>riesgo_corrupcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   costo_total  plazo_meses  adicionales_pct  ampliaciones  penalidades  \\\n",
       "0          NaN          NaN              NaN           NaN          NaN   \n",
       "1          NaN          NaN              NaN           NaN          NaN   \n",
       "2          NaN          NaN              NaN           NaN          NaN   \n",
       "\n",
       "   baja_competencia  empresa_sancionada  consorcio  experiencia_entidad  \\\n",
       "0               NaN                   0        NaN                  NaN   \n",
       "1               NaN                   0        NaN                  NaN   \n",
       "2               NaN                   0        NaN                  NaN   \n",
       "\n",
       "  region_riesgo  tipo_proceso  riesgo_corrupcion  \n",
       "0         MEDIA           NaN               <NA>  \n",
       "1         MEDIA           NaN               <NA>  \n",
       "2         MEDIA           NaN               <NA>  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# == 3) GOLD (features + etiqueta si existe)\n",
    "features_needed = [\n",
    "    \"costo_total\",\n",
    "    \"plazo_meses\",\n",
    "    \"adicionales_pct\",\n",
    "    \"ampliaciones\",\n",
    "    \"penalidades\",\n",
    "    \"baja_competencia\",\n",
    "    \"empresa_sancionada\",\n",
    "    \"consorcio\",\n",
    "    \"experiencia_entidad\",\n",
    "    \"region_riesgo\",\n",
    "    \"tipo_proceso\",\n",
    "]\n",
    "label_col = \"riesgo_corrupcion\"\n",
    "\n",
    "for c in features_needed:\n",
    "    if c not in obra.columns:\n",
    "        obra[c] = np.nan\n",
    "\n",
    "if label_col in obra.columns:\n",
    "    obra[label_col] = pd.to_numeric(obra[label_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "df = obra[features_needed + ([label_col] if label_col in obra.columns else [])].copy()\n",
    "print(\"GOLD df shape:\", df.shape)\n",
    "save_df(df, Path(\"data/gold/obras_ml\"))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebfada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == 4) ETL + Entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    RocCurveDisplay,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def winsorize(s: pd.Series, p_low=0.01, p_high=0.99):\n",
    "    lo, hi = s.quantile(p_low), s.quantile(p_high)\n",
    "    return s.clip(lo, hi)\n",
    "\n",
    "\n",
    "raw = df.copy()\n",
    "for c in [\"costo_total\", \"plazo_meses\", \"adicionales_pct\", \"ampliaciones\", \"penalidades\"]:\n",
    "    if c in raw.columns:\n",
    "        raw[c] = winsorize(pd.to_numeric(raw[c], errors=\"coerce\"))\n",
    "\n",
    "raw[\"flag_adicionales_altos\"] = (raw[\"adicionales_pct\"] > 0.15).astype(\"Int64\")\n",
    "raw[\"flag_muchas_ampliaciones\"] = (raw[\"ampliaciones\"] >= 2).astype(\"Int64\")\n",
    "raw[\"flag_penalidades\"] = (raw[\"penalidades\"] >= 1).astype(\"Int64\")\n",
    "raw[\"flag_contratacion_directa\"] = (raw[\"tipo_proceso\"] == \"Contratación Directa\").astype(\"Int64\")\n",
    "raw[\"flag_region_alta\"] = (raw[\"region_riesgo\"] == \"ALTA\").astype(\"Int64\")\n",
    "\n",
    "\n",
    "def synth_label(d: pd.DataFrame, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    score = (\n",
    "        0.5 * (d[\"adicionales_pct\"] > 0.15).astype(int)\n",
    "        + 0.4 * (d[\"ampliaciones\"] >= 2).astype(int)\n",
    "        + 0.3 * d[\"empresa_sancionada\"].fillna(0).astype(int)\n",
    "        + 0.25 * d[\"baja_competencia\"].fillna(0).astype(int)\n",
    "        + 0.2 * (d[\"penalidades\"] >= 1).astype(int)\n",
    "        + 0.15 * (d[\"tipo_proceso\"] == \"Contratación Directa\").astype(int)\n",
    "        + 0.1 * (d[\"region_riesgo\"] == \"ALTA\").astype(int)\n",
    "        + 0.05 * d[\"consorcio\"].fillna(0).astype(int)\n",
    "    )\n",
    "    prob = 1 / (1 + np.exp(-(score + rng.normal(0, 0.3, len(d)))))\n",
    "    return (prob > 0.55).astype(int)\n",
    "\n",
    "\n",
    "if \"riesgo_corrupcion\" in raw.columns and raw[\"riesgo_corrupcion\"].notna().any():\n",
    "    raw[\"riesgo_corrupcion\"] = raw[\"riesgo_corrupcion\"].fillna(0).astype(int)\n",
    "else:\n",
    "    print(\"[INFO] No hay etiqueta histórica -> se sintetiza para entrenar.\")\n",
    "    raw[\"riesgo_corrupcion\"] = synth_label(raw)\n",
    "\n",
    "target = \"riesgo_corrupcion\"\n",
    "features = [c for c in raw.columns if c != target]\n",
    "X = raw[features].copy()\n",
    "y = raw[target].astype(int)\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "bin_cols = [\n",
    "    c for c in X.columns if X[c].dropna().nunique() == 2 and X[c].dtype not in (object, \"category\")\n",
    "]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols + bin_cols]\n",
    "\n",
    "numeric = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "categorical = Pipeline(steps=[(\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [(\"num\", numeric, num_cols), (\"cat\", categorical, cat_cols), (\"pass\", \"passthrough\", bin_cols)]\n",
    ")\n",
    "\n",
    "assert len(X) > 0, \"Dataset vacío. Revisa DATA_ROOT/patrones.\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def evaluar(modelo: Pipeline, Xtr, ytr, Xte, yte, name=\"modelo\"):\n",
    "    modelo.fit(Xtr, ytr)\n",
    "    ypro = modelo.predict_proba(Xte)[:, 1]\n",
    "    yhat = (ypro >= 0.5).astype(int)\n",
    "    roc = roc_auc_score(yte, ypro)\n",
    "    pr = average_precision_score(yte, ypro)\n",
    "    print(f\"== {name} ==\")\n",
    "    print(\"ROC-AUC:\", round(roc, 4), \" PR-AUC:\", round(pr, 4))\n",
    "    print(\"\\\\n\", classification_report(yte, yhat, digits=4))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    RocCurveDisplay.from_predictions(yte, ypro, ax=ax)\n",
    "    ax.set_title(f\"ROC — {name}\")\n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots()\n",
    "    PrecisionRecallDisplay.from_predictions(yte, ypro, ax=ax)\n",
    "    ax.set_title(f\"PR — {name}\")\n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay.from_predictions(yte, yhat, ax=ax)\n",
    "    ax.set_title(f\"Matriz — {name}\")\n",
    "    plt.show()\n",
    "    try:\n",
    "        print(\"Brier:\", round(brier_score_loss(yte, ypro), 4))\n",
    "    except:\n",
    "        pass\n",
    "    return {\"roc_auc\": roc, \"pr_auc\": pr, \"model\": modelo}\n",
    "\n",
    "\n",
    "baseline = Pipeline(\n",
    "    [\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", LogisticRegression(max_iter=300, class_weight=\"balanced\", solver=\"liblinear\")),\n",
    "    ]\n",
    ")\n",
    "res_base = evaluar(baseline, X_train, y_train, X_test, y_test, \"Baseline — RegLog\")\n",
    "\n",
    "rf_pipe = Pipeline(\n",
    "    [(\"prep\", preprocess), (\"rf\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"rf__n_estimators\": [200, 350],\n",
    "    \"rf__max_depth\": [None, 10],\n",
    "    \"rf__min_samples_split\": [2, 10],\n",
    "    \"rf__min_samples_leaf\": [1, 3],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "gs = GridSearchCV(rf_pipe, param_grid, scoring=\"average_precision\", cv=cv, n_jobs=-1, verbose=0)\n",
    "gs.fit(X_train, y_train)\n",
    "best_rf = gs.best_estimator_\n",
    "res_rf = evaluar(best_rf, X_train, y_train, X_test, y_test, \"RandomForest (mejor)\")\n",
    "print(\"Mejores params RF:\", gs.best_params_)\n",
    "\n",
    "best = res_rf if res_rf[\"pr_auc\"] >= res_base[\"pr_auc\"] else res_base\n",
    "best_name = \"RandomForest\" if best is res_rf else \"RegLog\"\n",
    "best_model = best[\"model\"]\n",
    "print(\n",
    "    \"Modelo seleccionado:\",\n",
    "    best_name,\n",
    "    \"PR-AUC:\",\n",
    "    round(best[\"pr_auc\"], 4),\n",
    "    \" ROC-AUC:\",\n",
    "    round(best[\"roc_auc\"], 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adcaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == 5) XAI\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.inspection import PartialDependenceDisplay, permutation_importance\n",
    "\n",
    "try:\n",
    "    pi = permutation_importance(best_model, X_test, y_test, n_repeats=5, random_state=42, n_jobs=-1)\n",
    "    importances = pi.importances_mean\n",
    "\n",
    "    def get_feature_names(ct, input_features):\n",
    "        out = []\n",
    "        for name, trans, cols in ct.transformers_:\n",
    "            if name == \"pass\" and trans == \"passthrough\":\n",
    "                out.extend(cols if isinstance(cols, list) else [cols])\n",
    "            else:\n",
    "                if hasattr(trans, \"get_feature_names_out\"):\n",
    "                    out.extend(trans.get_feature_names_out(cols))\n",
    "                else:\n",
    "                    out.extend(cols if isinstance(cols, list) else [cols])\n",
    "        return [str(x) for x in out]\n",
    "\n",
    "    feat_names = get_feature_names(best_model.named_steps[\"prep\"], X_test.columns)\n",
    "    idx = np.argsort(importances)[::-1][:20]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(range(len(idx)), importances[idx])\n",
    "    ax.set_xticks(range(len(idx)))\n",
    "    ax.set_xticklabels(\n",
    "        [feat_names[i] if i < len(feat_names) else f\"f{i}\" for i in idx], rotation=90\n",
    "    )\n",
    "    ax.set_title(\"Importancia por permutación (Top 20)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Importancia no disponible:\", e)\n",
    "\n",
    "num_candidates = [c for c in X_test.columns if pd.api.types.is_numeric_dtype(X_test[c])][:3]\n",
    "for feat in num_candidates:\n",
    "    try:\n",
    "        fig, ax = plt.subplots()\n",
    "        PartialDependenceDisplay.from_estimator(best_model, X_test, [feat], ax=ax)\n",
    "        ax.set_title(f\"PDP — {feat}\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] PDP falló\", feat, \"->\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecb1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == 6) Exportar artefactos\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "PIPE_PATH = ARTIF_DIR / \"preprocess_pipeline.joblib\"\n",
    "MODEL_PATH = ARTIF_DIR / \"model.joblib\"\n",
    "META_PATH = ARTIF_DIR / \"metadata.json\"\n",
    "\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "try:\n",
    "    joblib.dump(best_model.named_steps[\"prep\"], PIPE_PATH)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "meta = {\n",
    "    \"model\": best_name,\n",
    "    \"metrics\": {\"roc_auc\": float(best[\"roc_auc\"]), \"pr_auc\": float(best[\"pr_auc\"])},\n",
    "    \"features\": X.columns.tolist(),\n",
    "    \"target\": \"riesgo_corrupcion\",\n",
    "}\n",
    "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "MODEL_PATH, META_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == 7) Inferencia rápida\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def predict_df(df_new: pd.DataFrame, model_path=\"artifacts/model.joblib\"):\n",
    "    model = joblib.load(model_path)\n",
    "    p = model.predict_proba(df_new)[:, 1]\n",
    "    out = df_new.copy()\n",
    "    out[\"prob_riesgo\"] = p\n",
    "    out[\"pred_riesgo\"] = (p >= 0.5).astype(int)\n",
    "    return out\n",
    "\n",
    "\n",
    "try:\n",
    "    predict_df(X_test.head(3)).head()\n",
    "except Exception as e:\n",
    "    print(\"[INFO] Sin muestra:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

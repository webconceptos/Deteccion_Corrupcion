==========================================================
 üß† Semana 6 ‚Äì Pipeline completo de modelado predictivo
 Log: reports/logs/semana6_run_20251106_161502.log
==========================================================

[16:15:03] ‚ñ∂Ô∏è  üì¶ [1/9] Construyendo datasets...
Comando: python scripts/build_dataset_ml.py && python scripts/build_dataset_integrado.py

=== [1] CARGA DE FUENTES ===
‚úÖ Cargado DS_DASH_Obra_1A.csv                      ‚Üí 326 filas, 13 cols
‚úÖ Cargado DS_DASH_Obra_2A_3A.csv                   ‚Üí 552 filas, 23 cols
‚úÖ Cargado DS_DASH_Obra_2B.csv                      ‚Üí 1613 filas, 7 cols
‚úÖ Cargado DS_DASH_Obra_3B.csv                      ‚Üí 5249 filas, 21 cols
‚úÖ Cargado DS_DASH_Obra_3C.csv                      ‚Üí 5249 filas, 9 cols
‚úÖ Cargado DS_DASH_Obra_4A.csv                      ‚Üí 326 filas, 10 cols
‚úÖ Cargado DS_DASH_Obra_4B.csv                      ‚Üí 326 filas, 16 cols
‚úÖ Cargado DS_DASH_Obra_5A.csv                      ‚Üí 634 filas, 16 cols
‚úÖ Cargado DS_DASH_Empresa_1A.csv                   ‚Üí 553 filas, 10 cols
‚úÖ Cargado DS_DASH_Empresa_1B.csv                   ‚Üí 2148 filas, 6 cols
‚úÖ Cargado DS_DASH_Empresa_2A.csv                   ‚Üí 371 filas, 12 cols
‚úÖ Cargado DS_DASH_Empresa_2B.csv                   ‚Üí 5395 filas, 5 cols
‚úÖ Cargado DS_DASH_Empresa_2C.csv                   ‚Üí 26 filas, 3 cols
‚úÖ Cargado DS_DASH_Miembro_1A.csv                   ‚Üí 1613 filas, 11 cols
‚úÖ Cargado DS_DASH_Miembro_2A.csv                   ‚Üí 739 filas, 9 cols
‚úÖ Cargado DS_DASH_Miembro_3A.csv                   ‚Üí 2606 filas, 5 cols
‚úÖ Cargado DS_DASH_Miembro_3B.csv                   ‚Üí 643 filas, 5 cols

üìä Obras: (14179, 56), Empresas: (8202, 26), Funcionarios: (5317, 17)

=== [2] CARGA DE PERFILAMIENTO DE RIESGO ===
‚úÖ Perfilamiento de riesgo: perfilamiento_obra_riesgosa.xlsx         (42 filas)
‚úÖ Perfilamiento de riesgo: perfilamiento_empresa_riesgosa.xlsx      (10 filas)

=== [3] UNIFICACI√ìN DE FUENTES ===
üîó Uni√≥n con riesgo_obra por ETAPA
‚úÖ Dataset unificado temporal: 14179 filas, 71 columnas

=== [4] CREACI√ìN DE VARIABLE OBJETIVO (y_riesgo) ===
‚úÖ Etiqueta creada desde columna existente: RIESGO_OBRA

=== [5] SELECCI√ìN DE VARIABLES ===

=== [6] LIMPIEZA FINAL ===

‚úÖ Dataset final guardado en: data\processed\dataset_obras.parquet
   ‚Üí 14179 filas, 30 columnas

=== [1] CARGA DE FUENTES ===
‚úÖ Cargado DS_DASH_Obra_1A.csv                 ‚Üí (326, 13)
‚úÖ Cargado DS_DASH_Obra_2A_3A.csv              ‚Üí (552, 23)
‚úÖ Cargado DS_DASH_Obra_2B.csv                 ‚Üí (1613, 7)
‚úÖ Cargado DS_DASH_Obra_3B.csv                 ‚Üí (5249, 21)
‚úÖ Cargado DS_DASH_Obra_3C.csv                 ‚Üí (5249, 9)
‚úÖ Cargado DS_DASH_Obra_4A.csv                 ‚Üí (326, 10)
‚úÖ Cargado DS_DASH_Obra_4B.csv                 ‚Üí (326, 16)
‚úÖ Cargado DS_DASH_Obra_5A.csv                 ‚Üí (634, 16)
‚úÖ Cargado DS_DASH_Empresa_1A.csv              ‚Üí (553, 10)
‚úÖ Cargado DS_DASH_Empresa_1B.csv              ‚Üí (2148, 6)
‚úÖ Cargado DS_DASH_Empresa_2A.csv              ‚Üí (371, 12)
‚úÖ Cargado DS_DASH_Empresa_2B.csv              ‚Üí (5395, 5)
‚úÖ Cargado DS_DASH_Empresa_2C.csv              ‚Üí (26, 3)
‚úÖ Cargado DS_DASH_Miembro_1A.csv              ‚Üí (1613, 11)
‚úÖ Cargado DS_DASH_Miembro_2A.csv              ‚Üí (739, 9)
‚úÖ Cargado DS_DASH_Miembro_3A.csv              ‚Üí (2606, 5)
‚úÖ Cargado DS_DASH_Miembro_3B.csv              ‚Üí (643, 5)
üìä Obras: (14179, 56), Empresas: (8202, 26), Funcionarios: (5317, 17)

=== [2] CARGA DE PERFILAMIENTOS ===
‚úÖ Cargado perfilamiento: perfilamiento_obra_riesgosa.xlsx    ((42, 16))
‚úÖ Cargado perfilamiento: perfilamiento_empresa_riesgosa.xlsx ((10, 11))

=== [3] ETIQUETAS DE RIESGO POR DOMINIO ===
‚ö†Ô∏è Etiqueta simulada generada.
‚ö†Ô∏è Etiqueta simulada generada.
‚ö†Ô∏è Etiqueta simulada generada.

=== [4] NORMALIZACI√ìN DE LLAVES ===
‚úÖ OBRA normalizado ((14179, 57))
‚úÖ EMPRESA normalizado ((8202, 27))
‚úÖ FUNCIONARIO normalizado ((5317, 18))

=== [5] FUSI√ìN DE FUENTES ===
üìä Dataset integrado temporal: (14179, 57)

=== [6] LIMPIEZA Y SELECCI√ìN DE VARIABLES ===

=== [7] EXPORTACI√ìN ===
‚úÖ Dataset integrado guardado en: data\processed\dataset_integrado.parquet
   ‚Üí 14179 filas, 56 columnas
‚úÖ Completado: üì¶ [1/9] Construyendo datasets...

[16:15:13] ‚ñ∂Ô∏è  ü§ñ [2/9] Entrenando modelos...
Comando: python scripts/train_models.py --folds 5
D:\IA_Investigacion\Deteccion_Corrupcion\env\Lib\site-packages\sklearn\linear_model\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=1000).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
D:\IA_Investigacion\Deteccion_Corrupcion\env\Lib\site-packages\sklearn\linear_model\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=1000).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
D:\IA_Investigacion\Deteccion_Corrupcion\env\Lib\site-packages\sklearn\linear_model\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=1000).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
D:\IA_Investigacion\Deteccion_Corrupcion\env\Lib\site-packages\sklearn\linear_model\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=1000).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
D:\IA_Investigacion\Deteccion_Corrupcion\env\Lib\site-packages\sklearn\linear_model\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=1000).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
D:\IA_Investigacion\Deteccion_Corrupcion\env\Lib\site-packages\sklearn\linear_model\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=1000).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

=== [1] CARGA DE DATOS ===
Dataset: 14179 filas, 56 columnas

=== [2] ENTRENAMIENTO CRUZADO ===
‚úÖ logreg  ‚Üí F1=0.356 | ROC_AUC=0.500 | PR_AUC=0.310 | Tiempo=473.5s
‚úÖ rf      ‚Üí F1=0.207 | ROC_AUC=0.490 | PR_AUC=0.303 | Tiempo=1280.2s
‚úÖ xgb     ‚Üí F1=0.065 | ROC_AUC=0.503 | PR_AUC=0.312 | Tiempo=260.6s

üìä Resultados guardados en reports\metrics_semana6.csv (3 registros totales)
üèÜ Mejor modelo: LOGREG (F1=0.356)
üìÅ Artefactos guardados en: models

‚è± Tiempo total: 2107.7s
‚úÖ Completado: ü§ñ [2/9] Entrenando modelos...

[16:50:28] ‚ñ∂Ô∏è  üìà [3/9] Analizando resultados y m√©tricas...
Comando: python scripts/plot_importance.py && python scripts/plot_calibration.py && python scripts/plot_learning_curves.py
=== Cargando modelo y datos ===
Traceback (most recent call last):
  File "D:\IA_Investigacion\Deteccion_Corrupcion\scripts\plot_importance.py", line 27, in <module>
    print("\u26a0\ufe0f El modelo no es XGBoost. Este script est· optimizado para XGBClassifier.")
  File "C:\Python312\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode characters in position 0-1: character maps to <undefined>
